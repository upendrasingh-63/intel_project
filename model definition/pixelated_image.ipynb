{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGjU0MjiLcHP",
        "outputId": "4112e592-bbd5-4640-bf9c-f49bb96b15b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.82)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define paths (use Google Drive for storage)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "original_images_path = '/content/drive/MyDrive/pixelation/original_images'\n",
        "pixelated_images_path = '/content/drive/MyDrive/pixelation/pixelated_images'\n",
        "dataset_path = '/content/drive/MyDrive/pixelation/dataset'\n",
        "\n",
        "# Create pixelated images\n",
        "def create_pixelated_images():\n",
        "    if not os.path.exists(pixelated_images_path):\n",
        "        os.makedirs(pixelated_images_path)\n",
        "\n",
        "    for filename in os.listdir(original_images_path):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "            img = cv2.imread(os.path.join(original_images_path, filename))\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # JPEG compression\n",
        "            for quality in [10, 20]:\n",
        "                compressed_img_path = os.path.join(pixelated_images_path, f'{filename}_quality_{quality}.jpg')\n",
        "                cv2.imwrite(compressed_img_path, img, [int(cv2.IMWRITE_JPEG_QUALITY), quality])\n",
        "\n",
        "            # Downscale-upscale\n",
        "            for scale in [5, 6]:\n",
        "                downscaled_img = cv2.resize(img, (img.shape[1]//scale, img.shape[0]//scale), interpolation=cv2.INTER_NEAREST)\n",
        "                upscaled_img = cv2.resize(downscaled_img, (img.shape[1], img.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "                upscaled_img_path = os.path.join(pixelated_images_path, f'{filename}_scale_{scale}.jpg')\n",
        "                cv2.imwrite(upscaled_img_path, upscaled_img)\n",
        "\n",
        "create_pixelated_images()\n",
        "\n",
        "# Prepare dataset\n",
        "def prepare_dataset():\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    # Load original images\n",
        "    for filename in tqdm(os.listdir(original_images_path)):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "            img = cv2.imread(os.path.join(original_images_path, filename))\n",
        "            if img is not None:\n",
        "                images.append(cv2.resize(img, (224, 224)))\n",
        "                labels.append(0)  # Label 0 for original images\n",
        "\n",
        "    # Load pixelated images\n",
        "    for filename in tqdm(os.listdir(pixelated_images_path)):\n",
        "        if filename.endswith('.jpg'):\n",
        "            img = cv2.imread(os.path.join(pixelated_images_path, filename))\n",
        "            if img is not None:\n",
        "                images.append(cv2.resize(img, (224, 224)))\n",
        "                labels.append(1)  # Label 1 for pixelated images\n",
        "\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # Split the dataset\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "    np.save(os.path.join(dataset_path, 'X_train.npy'), X_train)\n",
        "    np.save(os.path.join(dataset_path, 'y_train.npy'), y_train)\n",
        "    np.save(os.path.join(dataset_path, 'X_val.npy'), X_val)\n",
        "    np.save(os.path.join(dataset_path, 'y_val.npy'), y_val)\n",
        "    np.save(os.path.join(dataset_path, 'X_test.npy'), X_test)\n",
        "    np.save(os.path.join(dataset_path, 'y_test.npy'), y_test)\n",
        "\n",
        "prepare_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R048OffCLxV9",
        "outputId": "aaf89c88-27bb-48af-848e-7db42bee7d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 229/229 [00:09<00:00, 23.20it/s]\n",
            "100%|██████████| 860/860 [00:38<00:00, 22.59it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load dataset\n",
        "dataset_path = '/content/drive/MyDrive/pixelation/dataset'\n",
        "X_train = np.load(os.path.join(dataset_path, 'X_train.npy'))\n",
        "y_train = np.load(os.path.join(dataset_path, 'y_train.npy'))\n",
        "X_val = np.load(os.path.join(dataset_path, 'X_val.npy'))\n",
        "y_val = np.load(os.path.join(dataset_path, 'y_val.npy'))\n",
        "X_test = np.load(os.path.join(dataset_path, 'X_test.npy'))\n",
        "y_test = np.load(os.path.join(dataset_path, 'y_test.npy'))\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Build the model\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=batch_size),\n",
        "    steps_per_epoch=len(X_train) // batch_size,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=epochs\n",
        ")\n",
        "\n",
        "# Unfreeze the base model for fine-tuning\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Re-compile the model\n",
        "model.compile(optimizer=Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Continue training\n",
        "model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=batch_size),\n",
        "    steps_per_epoch=len(X_train) // batch_size,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model_path = '/content/drive/MyDrive/pixelation/pixelation_detection_model.h5'\n",
        "model.save(model_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJIp-16Xiv-8",
        "outputId": "058a108f-93a7-4272-c8d7-8777a020daca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "26/26 [==============================] - 49s 2s/step - loss: 0.6286 - accuracy: 0.7222 - val_loss: 0.5509 - val_accuracy: 0.7850\n",
            "Epoch 2/10\n",
            "26/26 [==============================] - 47s 2s/step - loss: 0.5405 - accuracy: 0.7983 - val_loss: 0.5327 - val_accuracy: 0.7850\n",
            "Epoch 3/10\n",
            "26/26 [==============================] - 47s 2s/step - loss: 0.5129 - accuracy: 0.7911 - val_loss: 0.5415 - val_accuracy: 0.7850\n",
            "Epoch 4/10\n",
            "26/26 [==============================] - 44s 2s/step - loss: 0.4867 - accuracy: 0.7995 - val_loss: 0.5517 - val_accuracy: 0.7850\n",
            "Epoch 5/10\n",
            "26/26 [==============================] - 47s 2s/step - loss: 0.4770 - accuracy: 0.8031 - val_loss: 0.5506 - val_accuracy: 0.7850\n",
            "Epoch 6/10\n",
            "26/26 [==============================] - 48s 2s/step - loss: 0.5008 - accuracy: 0.7899 - val_loss: 0.5385 - val_accuracy: 0.7850\n",
            "Epoch 7/10\n",
            "26/26 [==============================] - 48s 2s/step - loss: 0.4848 - accuracy: 0.7983 - val_loss: 0.5306 - val_accuracy: 0.7850\n",
            "Epoch 8/10\n",
            "26/26 [==============================] - 47s 2s/step - loss: 0.4773 - accuracy: 0.8007 - val_loss: 0.5472 - val_accuracy: 0.7757\n",
            "Epoch 9/10\n",
            "26/26 [==============================] - 45s 2s/step - loss: 0.4811 - accuracy: 0.7935 - val_loss: 0.5384 - val_accuracy: 0.7850\n",
            "Epoch 10/10\n",
            "26/26 [==============================] - 45s 2s/step - loss: 0.4807 - accuracy: 0.7959 - val_loss: 0.5454 - val_accuracy: 0.7850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "26/26 [==============================] - 174s 6s/step - loss: 0.5349 - accuracy: 0.7874 - val_loss: 0.5798 - val_accuracy: 0.7850\n",
            "Epoch 2/10\n",
            "26/26 [==============================] - 154s 6s/step - loss: 0.4388 - accuracy: 0.7959 - val_loss: 0.5290 - val_accuracy: 0.7850\n",
            "Epoch 3/10\n",
            "26/26 [==============================] - 147s 6s/step - loss: 0.4376 - accuracy: 0.7983 - val_loss: 0.6414 - val_accuracy: 0.7196\n",
            "Epoch 4/10\n",
            "26/26 [==============================] - 141s 5s/step - loss: 0.3948 - accuracy: 0.8345 - val_loss: 1.6115 - val_accuracy: 0.2243\n",
            "Epoch 5/10\n",
            "26/26 [==============================] - 146s 6s/step - loss: 0.3965 - accuracy: 0.8321 - val_loss: 0.4772 - val_accuracy: 0.7570\n",
            "Epoch 6/10\n",
            "26/26 [==============================] - 147s 6s/step - loss: 0.3527 - accuracy: 0.8522 - val_loss: 1.4010 - val_accuracy: 0.2897\n",
            "Epoch 7/10\n",
            "26/26 [==============================] - 145s 6s/step - loss: 0.3524 - accuracy: 0.8394 - val_loss: 0.9299 - val_accuracy: 0.2710\n",
            "Epoch 8/10\n",
            "26/26 [==============================] - 148s 6s/step - loss: 0.3480 - accuracy: 0.8394 - val_loss: 0.6329 - val_accuracy: 0.7477\n",
            "Epoch 9/10\n",
            "26/26 [==============================] - 142s 5s/step - loss: 0.3337 - accuracy: 0.8442 - val_loss: 0.6201 - val_accuracy: 0.7850\n",
            "Epoch 10/10\n",
            "26/26 [==============================] - 144s 5s/step - loss: 0.3166 - accuracy: 0.8635 - val_loss: 0.6835 - val_accuracy: 0.4486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the trained model\n",
        "model_path = '/content/drive/MyDrive/pixelation/pixelation_detection_model.h5'\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# Convert the model to TensorFlow Lite format\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the optimized model\n",
        "tflite_model_path = '/content/drive/MyDrive/pixelation/pixelation_detection_model.tflite'\n",
        "with open(tflite_model_path, 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "# Example code for running inference on a TFLite model\n",
        "def run_inference(image_path, model_path):\n",
        "    # Load the TFLite model and allocate tensors\n",
        "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    # Get input and output tensors\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    # Prepare the image\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    img = np.expand_dims(img, axis=0).astype(np.float32)\n",
        "\n",
        "    # Run inference\n",
        "    interpreter.set_tensor(input_details[0]['index'], img)\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Get the result\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "    prediction = output_data[0]\n",
        "\n",
        "    return 'Pixelated' if prediction > 0.5 else 'Non-Pixelated'\n",
        "\n",
        "# Test the inference function\n",
        "test_image_path = '/content/drive/MyDrive/pixelation/pixelated_images/cherry_37.jpg_quality_10.jpg'\n",
        "print(run_inference(test_image_path, tflite_model_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-smC4QrJvJLl",
        "outputId": "02412276-11ca-4b11-dacf-315c77182a69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pixelated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_path = '/content/drive/MyDrive/pixelation/pixelated_images/cherry_37.jpg_scale_5.jpg'\n",
        "print(run_inference(test_image_path, tflite_model_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaeGTfD1wObj",
        "outputId": "7f4325a6-cef1-43bd-a411-6774fe0eb9c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-Pixelated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(tflite_model_path):\n",
        "    model_size = os.path.getsize(tflite_model_path)\n",
        "    print(f\"Model size: {model_size / (1024 * 1024):.2f} MB\")  # Convert to MB\n",
        "else:\n",
        "    print(\"Model file not found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCc-yaCtw9ka",
        "outputId": "f883d23e-1a35-477c-9120-5c8d17cd6bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model size: 9.07 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.applications.MobileNetV2()  # Example model\n",
        "\n",
        "# Save the model to a temporary file\n",
        "model.save('/tmp/model')\n",
        "\n",
        "# Calculate the size of the saved model file\n",
        "model_size = os.path.getsize('/tmp/model')\n",
        "print(f\"Model size: {model_size / (1024 * 1024):.2f} MB\")  # Convert to MB\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjwwBzaVxOUT",
        "outputId": "2ecfccc7-64df-4625-9501-ab023f13abdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n",
            "14536120/14536120 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model size: 0.00 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Assume `model` is already loaded and ready for inference\n",
        "\n",
        "# Example inference timing\n",
        "start_time = time.time()\n",
        "test_image_path = '/content/drive/MyDrive/pixelation/pixelated_images/cherry_37.jpg_quality_10.jpg'\n",
        "print(run_inference(test_image_path, tflite_model_path))\n",
        "end_time = time.time()\n",
        "\n",
        "inference_time = end_time - start_time\n",
        "fps = 1 / inference_time\n",
        "\n",
        "print(f\"Inference Time: {inference_time:.4f} seconds\")\n",
        "print(f\"FPS: {fps:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkeXXGtmzBgu",
        "outputId": "ea7ff2ec-2f8d-4aa3-a23a-af30ab6970a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pixelated\n",
            "Inference Time: 0.2169 seconds\n",
            "FPS: 4.61\n"
          ]
        }
      ]
    }
  ]
}